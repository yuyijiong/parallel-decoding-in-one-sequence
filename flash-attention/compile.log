nohup: ignoring input
/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.
!!

        ********************************************************************************
        Requirements should be satisfied by a PEP 517 installer.
        If you are using pip, you can try `pip install --use-pep517`.
        ********************************************************************************

!!
  dist.fetch_build_eggs(dist.setup_requires)


torch.__version__  = 2.6.0+cu124


running install
/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:79: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` directly.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
        ********************************************************************************

!!
  self.initialize_options()
/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:79: EasyInstallDeprecationWarning: easy_install command is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` and ``easy_install``.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        See https://github.com/pypa/setuptools/issues/917 for details.
        ********************************************************************************

!!
  self.initialize_options()
running bdist_egg
running egg_info
writing flash_attn.egg-info/PKG-INFO
writing dependency_links to flash_attn.egg-info/dependency_links.txt
writing requirements to flash_attn.egg-info/requires.txt
writing top-level names to flash_attn.egg-info/top_level.txt
reading manifest file 'flash_attn.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
warning: no files found matching '*.cu' under directory 'flash_attn'
warning: no files found matching '*.h' under directory 'flash_attn'
warning: no files found matching '*.cuh' under directory 'flash_attn'
warning: no files found matching '*.cpp' under directory 'flash_attn'
warning: no files found matching '*.hpp' under directory 'flash_attn'
adding license file 'LICENSE'
adding license file 'AUTHORS'
writing manifest file 'flash_attn.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
running build_ext
/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no g++ version bounds defined for CUDA version 12.4
  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
building 'flash_attn_2_cuda' extension
Emitting ninja build file /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Using envvar MAX_JOBS (128) as the number of workers...
[1/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim192_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[2/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim192_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[3/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim192_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[4/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim192_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[5/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim160_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[6/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim32_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[7/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim32_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[8/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim96_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[9/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim160_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[10/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[11/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[12/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim96_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[13/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[14/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim256_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[15/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim128_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[16/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim256_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[17/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim64_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[18/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[19/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[20/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim32_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[21/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim64_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[22/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim256_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[23/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim160_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[24/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim64_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[25/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim160_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[26/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[27/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim64_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[28/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[29/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim32_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[30/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[31/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[32/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim128_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[33/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[34/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim256_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[35/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[36/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[37/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim96_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[38/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[39/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[40/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim96_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[41/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim128_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[42/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[43/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[44/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[45/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[46/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[47/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[48/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[49/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[50/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[51/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[52/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim128_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[53/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[54/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[55/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[56/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[57/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[58/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[59/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[60/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[61/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[62/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[63/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[64/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[65/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[66/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[67/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[68/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[69/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[70/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[71/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[72/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[73/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[74/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[75/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_causal_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_causal_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_causal_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[76/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[77/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[78/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[79/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[80/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[81/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[82/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[83/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
[84/84] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.o.d -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn -I/data/yyj/flash-attention/flash-attention/csrc/flash_attn/src -I/data/yyj/flash-attention/flash-attention/csrc/cutlass/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/TH -I/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/envs/flash_attn_my/include/python3.10 -c -c /data/yyj/flash-attention/flash-attention/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.cu -o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -gencode arch=compute_80,code=sm_80 -gencode arch=compute_90,code=sm_90 --threads 2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
g++ -pthread -B /root/miniconda3/envs/flash_attn_my/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /root/miniconda3/envs/flash_attn_my/include -fPIC -O2 -isystem /root/miniconda3/envs/flash_attn_my/include -pthread -B /root/miniconda3/envs/flash_attn_my/compiler_compat -shared /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/flash_api.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim128_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim160_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim192_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim256_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim32_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim64_fp16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_bf16_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_causal_sm80.o /data/yyj/flash-attention/flash-attention/build/temp.linux-x86_64-cpython-310/csrc/flash_attn/src/flash_fwd_split_hdim96_fp16_sm80.o -L/root/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/fused_softmax.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/bert_padding.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_blocksparse_attn_interface.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_og.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_blocksparse_attention.py -> build/bdist.linux-x86_64/egg/flash_attn
creating build/bdist.linux-x86_64/egg/flash_attn/modules
copying build/lib.linux-x86_64-cpython-310/flash_attn/modules/block.py -> build/bdist.linux-x86_64/egg/flash_attn/modules
copying build/lib.linux-x86_64-cpython-310/flash_attn/modules/mlp.py -> build/bdist.linux-x86_64/egg/flash_attn/modules
copying build/lib.linux-x86_64-cpython-310/flash_attn/modules/embedding.py -> build/bdist.linux-x86_64/egg/flash_attn/modules
copying build/lib.linux-x86_64-cpython-310/flash_attn/modules/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/modules
copying build/lib.linux-x86_64-cpython-310/flash_attn/modules/mha.py -> build/bdist.linux-x86_64/egg/flash_attn/modules
creating build/bdist.linux-x86_64/egg/flash_attn/losses
copying build/lib.linux-x86_64-cpython-310/flash_attn/losses/cross_entropy.py -> build/bdist.linux-x86_64/egg/flash_attn/losses
copying build/lib.linux-x86_64-cpython-310/flash_attn/losses/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/losses
creating build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/btlm.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/falcon.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/gpt.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/bert.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/llama.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/gptj.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/opt.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/vit.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/bigcode.py -> build/bdist.linux-x86_64/egg/flash_attn/models
copying build/lib.linux-x86_64-cpython-310/flash_attn/models/baichuan.py -> build/bdist.linux-x86_64/egg/flash_attn/models
creating build/bdist.linux-x86_64/egg/flash_attn/ops
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/layer_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/activations.py -> build/bdist.linux-x86_64/egg/flash_attn/ops
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/ops
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/fused_dense.py -> build/bdist.linux-x86_64/egg/flash_attn/ops
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/rms_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops
creating build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/linear.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/cross_entropy.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/mlp.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/rotary.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/layer_norm.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/k_activations.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
copying build/lib.linux-x86_64-cpython-310/flash_attn/ops/triton/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/ops/triton
creating build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/bench.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/interface_torch.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/utils.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/test.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
copying build/lib.linux-x86_64-cpython-310/flash_attn/flash_attn_triton_amd/interface_fa.py -> build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd
creating build/bdist.linux-x86_64/egg/flash_attn/utils
copying build/lib.linux-x86_64-cpython-310/flash_attn/utils/generation.py -> build/bdist.linux-x86_64/egg/flash_attn/utils
copying build/lib.linux-x86_64-cpython-310/flash_attn/utils/distributed.py -> build/bdist.linux-x86_64/egg/flash_attn/utils
copying build/lib.linux-x86_64-cpython-310/flash_attn/utils/pretrained.py -> build/bdist.linux-x86_64/egg/flash_attn/utils
copying build/lib.linux-x86_64-cpython-310/flash_attn/utils/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/utils
copying build/lib.linux-x86_64-cpython-310/flash_attn/utils/benchmark.py -> build/bdist.linux-x86_64/egg/flash_attn/utils
creating build/bdist.linux-x86_64/egg/flash_attn/layers
copying build/lib.linux-x86_64-cpython-310/flash_attn/layers/rotary.py -> build/bdist.linux-x86_64/egg/flash_attn/layers
copying build/lib.linux-x86_64-cpython-310/flash_attn/layers/__init__.py -> build/bdist.linux-x86_64/egg/flash_attn/layers
copying build/lib.linux-x86_64-cpython-310/flash_attn/layers/patch_embed.py -> build/bdist.linux-x86_64/egg/flash_attn/layers
creating build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/benchmark_mla_decode.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/flash_attn_interface.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/benchmark_attn.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/test_attn_kvcache.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/test_kvcache.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/__init__.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/test_util.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/benchmark_split_kv.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/test_flash_attn.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/benchmark_flash_attention_fp8.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/setup.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/padding.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/hopper/generate_kernels.py -> build/bdist.linux-x86_64/egg/hopper
copying build/lib.linux-x86_64-cpython-310/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_interface.py to flash_attn_interface.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/fused_softmax.py to fused_softmax.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/bert_padding.py to bert_padding.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton.py to flash_attn_triton.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attn_interface.py to flash_blocksparse_attn_interface.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_og.py to flash_attn_triton_og.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_blocksparse_attention.py to flash_blocksparse_attention.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/block.py to block.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mlp.py to mlp.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/embedding.py to embedding.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/modules/mha.py to mha.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/cross_entropy.py to cross_entropy.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/losses/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/btlm.py to btlm.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/falcon.py to falcon.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt.py to gpt.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/bert.py to bert.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/llama.py to llama.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gptj.py to gptj.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/opt.py to opt.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/gpt_neox.py to gpt_neox.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/vit.py to vit.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/bigcode.py to bigcode.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/models/baichuan.py to baichuan.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/layer_norm.py to layer_norm.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/activations.py to activations.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/fused_dense.py to fused_dense.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/rms_norm.py to rms_norm.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/linear.py to linear.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/cross_entropy.py to cross_entropy.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/mlp.py to mlp.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/rotary.py to rotary.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/layer_norm.py to layer_norm.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/k_activations.py to k_activations.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/ops/triton/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/bwd_prefill.py to bwd_prefill.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/fwd_ref.py to fwd_ref.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/bench.py to bench.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/fwd_decode.py to fwd_decode.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/interface_torch.py to interface_torch.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/fwd_prefill.py to fwd_prefill.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/utils.py to utils.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/test.py to test.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/bwd_ref.py to bwd_ref.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/flash_attn_triton_amd/interface_fa.py to interface_fa.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/generation.py to generation.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/distributed.py to distributed.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/pretrained.py to pretrained.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/utils/benchmark.py to benchmark.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/rotary.py to rotary.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/flash_attn/layers/patch_embed.py to patch_embed.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/benchmark_mla_decode.py to benchmark_mla_decode.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/flash_attn_interface.py to flash_attn_interface.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/benchmark_attn.py to benchmark_attn.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/test_attn_kvcache.py to test_attn_kvcache.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/test_kvcache.py to test_kvcache.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/__init__.py to __init__.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/test_util.py to test_util.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/benchmark_split_kv.py to benchmark_split_kv.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/test_flash_attn.py to test_flash_attn.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/benchmark_flash_attention_fp8.py to benchmark_flash_attention_fp8.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/setup.py to setup.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/padding.py to padding.cpython-310.pyc
byte-compiling build/bdist.linux-x86_64/egg/hopper/generate_kernels.py to generate_kernels.cpython-310.pyc
creating stub loader for flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so
byte-compiling build/bdist.linux-x86_64/egg/flash_attn_2_cuda.py to flash_attn_2_cuda.cpython-310.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying flash_attn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO
copying flash_attn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying flash_attn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying flash_attn.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying flash_attn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt
zip_safe flag not set; analyzing archive contents...
__pycache__.flash_attn_2_cuda.cpython-310: module references __file__
hopper.__pycache__.generate_kernels.cpython-310: module references __file__
hopper.__pycache__.setup.cpython-310: module references __file__
creating 'dist/flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg
creating /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg
Extracting flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg to /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Adding flash-attn 2.7.4.post1 to easy-install.pth file
detected new path './flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg'

Installed /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/flash_attn-2.7.4.post1-py3.10-linux-x86_64.egg
Processing dependencies for flash-attn==2.7.4.post1
Searching for einops==0.8.1
Best match: einops 0.8.1
Processing einops-0.8.1-py3.10.egg
Adding einops 0.8.1 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/einops-0.8.1-py3.10.egg
Searching for torch==2.6.0
Best match: torch 2.6.0
Adding torch 2.6.0 to easy-install.pth file
Installing torchfrtrace script to /root/miniconda3/envs/flash_attn_my/bin
Installing torchrun script to /root/miniconda3/envs/flash_attn_my/bin

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for sympy==1.13.1
Best match: sympy 1.13.1
Adding sympy 1.13.1 to easy-install.pth file
Installing isympy script to /root/miniconda3/envs/flash_attn_my/bin

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for triton==3.2.0
Best match: triton 3.2.0
Adding triton 3.2.0 to easy-install.pth file
Installing proton script to /root/miniconda3/envs/flash_attn_my/bin
Installing proton-viewer script to /root/miniconda3/envs/flash_attn_my/bin

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-nvjitlink-cu12==12.4.127
Best match: nvidia-nvjitlink-cu12 12.4.127
Adding nvidia-nvjitlink-cu12 12.4.127 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-nvtx-cu12==12.4.127
Best match: nvidia-nvtx-cu12 12.4.127
Adding nvidia-nvtx-cu12 12.4.127 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-nccl-cu12==2.21.5
Best match: nvidia-nccl-cu12 2.21.5
Adding nvidia-nccl-cu12 2.21.5 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cusparselt-cu12==0.6.2
Best match: nvidia-cusparselt-cu12 0.6.2
Adding nvidia-cusparselt-cu12 0.6.2 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cusparse-cu12==12.3.1.170
Best match: nvidia-cusparse-cu12 12.3.1.170
Adding nvidia-cusparse-cu12 12.3.1.170 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cusolver-cu12==11.6.1.9
Best match: nvidia-cusolver-cu12 11.6.1.9
Adding nvidia-cusolver-cu12 11.6.1.9 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-curand-cu12==10.3.5.147
Best match: nvidia-curand-cu12 10.3.5.147
Adding nvidia-curand-cu12 10.3.5.147 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cufft-cu12==11.2.1.3
Best match: nvidia-cufft-cu12 11.2.1.3
Adding nvidia-cufft-cu12 11.2.1.3 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cublas-cu12==12.4.5.8
Best match: nvidia-cublas-cu12 12.4.5.8
Adding nvidia-cublas-cu12 12.4.5.8 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cudnn-cu12==9.1.0.70
Best match: nvidia-cudnn-cu12 9.1.0.70
Adding nvidia-cudnn-cu12 9.1.0.70 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cuda-cupti-cu12==12.4.127
Best match: nvidia-cuda-cupti-cu12 12.4.127
Adding nvidia-cuda-cupti-cu12 12.4.127 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cuda-runtime-cu12==12.4.127
Best match: nvidia-cuda-runtime-cu12 12.4.127
Adding nvidia-cuda-runtime-cu12 12.4.127 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for nvidia-cuda-nvrtc-cu12==12.4.127
Best match: nvidia-cuda-nvrtc-cu12 12.4.127
Adding nvidia-cuda-nvrtc-cu12 12.4.127 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for fsspec==2024.12.0
Best match: fsspec 2024.12.0
Adding fsspec 2024.12.0 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for jinja2==3.1.6
Best match: jinja2 3.1.6
Adding jinja2 3.1.6 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for networkx==3.4.2
Best match: networkx 3.4.2
Adding networkx 3.4.2 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for typing-extensions==4.12.2
Best match: typing-extensions 4.12.2
Adding typing-extensions 4.12.2 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages/setuptools/_vendor
Searching for filelock==3.18.0
Best match: filelock 3.18.0
Adding filelock 3.18.0 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for mpmath==1.3.0
Best match: mpmath 1.3.0
Adding mpmath 1.3.0 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Searching for MarkupSafe==3.0.2
Best match: MarkupSafe 3.0.2
Adding MarkupSafe 3.0.2 to easy-install.pth file

Using /data/miniconda3/envs/flash_attn_my/lib/python3.10/site-packages
Finished processing dependencies for flash-attn==2.7.4.post1
